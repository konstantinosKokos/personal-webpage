<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="en">
  <head>
    <title>Konstantinos Kogkalidis - Supertagging Beyond Trees with Heterogeneous Dynamic Convolutions </title>
    <meta charset="UTF-8">
    <link href="http://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="../css/all.css" />
  </head>

  <body>
    <div id="page">
      <div id="header">
          <ul class="nav-list">
  <li class="nav-elem nav-left nav-head">
    <a href="../"> Konstantinos Kogkalidis</a>
  </li>
  <li class="nav-elem nav-left ">
    <a href="../publications.html">Publications</a>
  </li>
  <li class="nav-elem nav-left ">
    <a href="../talks.html">Talks</a>
  </li>
  <li class="nav-elem nav-left">
    <a href="https://github.com/konstantinosKokos" target="_blank">GitHub</a>
  </li>
  <li class="nav-elem nav-left">
    <a href="../cv.pdf" target="_blank">Curriculum Vitae</a>
  </li>
  <!-- <li class="nav-elem nav-left ">
    <a href="/teaching.html">Teaching</a>
  </li> -->
</ul>

      </div>
      <div id="content">
            <h2>Supertagging Beyond Trees with Heterogeneous Dynamic Convolutions</h2>
<h3>
  
      <div>Presentation @ <a href="https://clin2022.uvt.nl/" <b>The 32nd Meeting of Computational Linguistics in the Netherlands</b></a></div>
  
  June 17, 2022
  
      <div><a href="https://raw.githubusercontent.com/konstantinosKokos/presentations/master/CLIN2022/main.pdf">Slides</a></div>
  
</h3>
<hr>
<p>
<p>The parsing pipeline in categorial grammar-based frameworks relies heavily on a supertagging component, a neural model that reads in a sentence and spits out a category assignment for each word; a correct assignment relieves the effort required to assemble constituents into a syntactically coherent unit.</p>
<p>A long-standing issue with supertagging architectures has been the sparsity of their training dataâ€“ categories with few occurrences are hard to learn, and tend to increase the classifierâ€™s vocabulary. As a counter-measure, the de facto approach would involve dropping such categories and limiting the scope of the system to categories (and corresponding syntactic phenomena) with a sufficiently high frequency.</p>
<p>More recently, the constructive approach proposes reducing the vocabulary to only the primitive symbols that participate in category formations, in turn representing categories as compositional entities (with their parts made explicit), rather than independent units. We argue that how one chooses to represent categories (and sequences thereof) makes a difference in the kinds of applicable architectures and the performances attainable.</p>
<p>Previously studied sequential models suffer from high memory and time complexity and relatively poor performance, whereas tree-recursive models fail to account for meaningful auto-regressive interactions between trees or otherwise require excessive CPU/GPU alterations. We propose a novel architecture whereby categorial trees are depth-wise decoded in parallel, their state tracked by one vector each. After each decoding step, state vectors receive feedback from their last decoded fringe before exchanging messages with one another, thereby informing the next iteration of both intra- and inter-tree dependencies. To account for the many disparate granularity scales in the graph (i.e.Â sentential word order, subword contextualized vectors, tree-sequence order and intra-tree edges), we opt for a heterogeneous attention-based formulation.</p>
<p>As a whole, our system boasts the combined merits of previous approaches, namely: high parallelism and fixed decoding time, a wide but memory bound perceptive field and a valid-by-construction output space that requires almost no structure manipulation to produce. We experimentally validate our approach by testing it on the two versions of the English CCGbank, the French TLGbank as well as the Dutch Ã†thel proofbank.</p>
<p>In every dataset considered, our system significantly outperforms the previous state-of-the-art scores by maintaining performance reaching or surpassing that of classification-based taggers on common categories, and constructive taggers on the tail end of the distribution.</p>
<p>We make our code publicly available at github.com/konstantinosKokos/dynamic-graph-supertagging.</p>
</p>

      </div>
    <div id="footer">
        <div class="foot-block foot-about">
  <div class="foot-head">About Me</div>
  I like ducks, drone metal, machine learning and type theory (in no particular order).
  I don't know much about either of these subjects.
</div>

<div class="foot-block foot-map">
  <div class="foot-head">Pages</div>
  <ul class="foot-list">
    <li class="foot-item">
      <a href="../index.html">Home</a>
    </li>
    <li class="foot-item">
      <a href="../publications.html">Publications</a>
    </li>
    <li class="foot-item">
      <a href="../talks.html">Talks</a>
    </li>
  </ul>
</div>

<div class="foot-block foot-map">
  <div class="foot-head">Profiles</div>
  <ul class="foot-list">
    <li class="foot-item">
      <a href="https://github.com/konstantinosKokos" target="_blank">
        Github</a>
    </li>
  </ul>
</div>

<div class="foot-madeby">
  <p>ðŸ„¯ Konstantinos Kogkalidis</p>
  Site proudly generated by
  <a href="http://jaspervdj.be/hakyll">Hakyll</a>
</div>

    </div>
  </div>
  </body>
  <script type="text/javascript" src="js/collapsible.js"></script>
</html>
